{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5deeb573-abd3-4819-bcfe-6c032179c03e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "## Projeto de extração de dados I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9864bbb3-40eb-46a1-bda5-2b2309644ec1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "**Resumo:** <br>\n",
    "* Campos: Genômica e medicina personalizada. <br>\n",
    "* Dados atualizados: (tendências, novidades e tratamentos) <br>\n",
    "* Fazer um processo para receber os dados, carregar e tratar essas informações."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd7440cf-8746-4b5a-a3e6-c3b6fff47790",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Instalando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d22e55-1d06-4673-a6e9-1da2eff4bcab",
     "showTitle": false,
     "title": ""
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#!pip install flask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "603505c9-7d0e-4d3d-9bd9-fe06ad21213a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "398fa4e6-ec2a-43c7-be13-efd0656a154d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vortex\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pyspark\\pandas\\__init__.py:50: UserWarning: 'PYARROW_IGNORE_TIMEZONE' environment variable was not set. It is required to set this environment variable to '1' in both driver and executor sides if you use pyarrow>=2.0.0. pandas-on-Spark will set it for you but it does not work if there is a Spark context already launched.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pyspark.dbutils'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m                     \u001b[38;5;66;03m# Requisições de API.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mps\u001b[39;00m         \u001b[38;5;66;03m# Trabalhar com dados estruturados.\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdbutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DBUtils \u001b[38;5;66;03m# Realizar operações ELT.\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mflask\u001b[39;00m                        \u001b[38;5;66;03m# Criar Webhook.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime       \u001b[38;5;66;03m# Trabalhar com datas.\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pyspark.dbutils'"
     ]
    }
   ],
   "source": [
    "import requests                     # Requisições de API.\n",
    "import pyspark.pandas as ps         # Trabalhar com dados estruturados.\n",
    "from pyspark.dbutils import DBUtils # Realizar operações ELT.\n",
    "import flask                        # Criar Webhook.\n",
    "from datetime import datetime       # Trabalhar com datas.\n",
    "import time as t                    # Trabalhar com tempos (Temporazidor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "72cf48e4-b4c5-4e4f-9613-bbcdd69622cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Definições e variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "34372d55-61bb-459d-abfd-4b1eadd97684",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Puxar Key da API.\n",
    "#%run ./api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "89eb00e8-0552-40b3-b50e-7b990d45e450",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Variáveis\n",
    "API_KEY='e5c81f8f38ac4f3587ad546b05240d1f'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5f0cbca3-ec29-413e-b13f-334544829a22",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Diretórios para cada camada da Arquitetura Midellion.\n",
    "dir_base = '/FileStore/tables/pasta5'               # Diretório base.\n",
    "dir_landing_zone = f'{dir_base}/landing_zone'      # Dados brutos da API.\n",
    "dir_bronze = f'{dir_base}/dado_consolidado.parquet' # Dados consolidados.\n",
    "dir_silver = f'{dir_base}/dado_limpo.parquet'       # Dado consolidado e limpos.\n",
    "dir_gold = f'{dir_base}/dado_transformado.parquet'  # Dado transformado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7402373d-ab53-4b66-8270-620fa47c08c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#dbutils.fs.rm('/FileStore/tables/ProjetoFinal/gold/', recurse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4842f82e-07cf-438e-bc59-28ece7008038",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Funções"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a8bbc97-c1ad-4f22-bb37-f31a496c76cc",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Função para Extração dos dados (Landing zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02e8fb13-cc1d-4cc1-8bcd-8a06a48250cd",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def consulta_api(current_datetime : str) -> dict:\n",
    "    \"\"\"\n",
    "    Consulta API e retorna os dados.\n",
    "    \n",
    "    Parâmetros:\n",
    "        current_datetime (str) : data para consulta.\n",
    "    \n",
    "    Retorno:\n",
    "        dados (dict): Dados da API.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parâmetros API.\n",
    "    by='popularity'\n",
    "\n",
    "    q_base = 'genome OR (personalized AND medicine)'\n",
    "    q_filtro1 = '(+DNA)'\n",
    "    q_filtro2 = '(+gene AND +therapies)'\n",
    "    q_filtro3 = '(+genetic AND +diseases)'\n",
    "    q_search = f'{q_base} AND ({q_filtro1} OR {q_filtro2} OR {q_filtro3})' \n",
    "    #q_search = 'crypto AND (ethereum OR litecoin) AND +bitcoin'\n",
    "\n",
    "    url = f'https://newsapi.org/v2/everything?q={q_search}&sortBy={by}&apiKey={API_KEY}&from={current_datetime}&to={current_datetime}'\n",
    "\n",
    "    # Buscar dados da API.\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200: # Caso consiga fazer a requisição.\n",
    "        dados = response.json()\n",
    "        \n",
    "        # Pegar os dados principais.\n",
    "        dados = dados['articles']\n",
    "        \n",
    "        if len(dados) > 0:\n",
    "            message = 'Aquisição de dados via API concluída'\n",
    "        else:\n",
    "            message = 'Sem dados de retorno via API'\n",
    "\n",
    "    else: # Caso tenha um código diferente de 200.\n",
    "        dados = None\n",
    "        message = 'Aquisição de dados via API falhou, código de status: ' + str(response.status_code) \n",
    "\n",
    "    return dados, message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27dcb609-e5e5-43e8-97ee-92252d9c9fd7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def melhora_dados_api(dados : dict) -> dict:\n",
    "    \"\"\"\n",
    "    Função que melhora os dados da API.\n",
    "    \n",
    "    Parâmetros:\n",
    "        dados (dict): Dados da API.\n",
    "        \n",
    "    Retorno:\n",
    "        dados (dict): Dados melhorados.\n",
    "    \"\"\"\n",
    "\n",
    "    # data da consulta.\n",
    "    data_atual = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "    # Para cada item.\n",
    "    for i in range(len(dados)):\n",
    "        # Arrumando a coluna 'source'.\n",
    "        name = dados[i]['source']['name']\n",
    "        dados[i]['source'] = name\n",
    "        \n",
    "        # Adicionar data atual no dicionário.\n",
    "        dados[i]['data_load'] = data_atual\n",
    "\n",
    "        # Criar uma key para cada item.\n",
    "        key = dados[i]['url'] + dados[i]['publishedAt']\n",
    "\n",
    "        # Adicionar key.\n",
    "        dados[i]['key'] = key\n",
    "\n",
    "    return dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "978dbf9a-056a-488b-bf1b-7bd8c1f34101",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def extract_data(current_datetime : str) -> ps.DataFrame:\n",
    "    \"\"\"\n",
    "    Função que extrai os dados da API e retorna um DataFrame, e salva um arquivo no diretório Landing_zone.\n",
    "    \n",
    "    Parâmetros:\n",
    "        current_datetime (str) : data para importar os dados.\n",
    "\n",
    "    Retorno:\n",
    "        df_result (ps.DataFrame): DataFrame com os dados extraídos da API.\n",
    "    \"\"\"\n",
    "\n",
    "    # Faz a consulta na API e retorna um dicionário.\n",
    "    dados, message = consulta_api(current_datetime)\n",
    "    \n",
    "    print(message) # Mostra a mensagem do retorno da API.\n",
    "    if dados:\n",
    "        # Melhorar dados e adiciona a Key.\n",
    "        dados = melhora_dados_api(dados)\n",
    "\n",
    "        # Transforma o dicionário em um DataFrame.\n",
    "        df_result = ps.DataFrame(dados) \n",
    "        \n",
    "        # Exportar os dados para um arquivo CSV na Landing Zone.\n",
    "        df_result.to_csv(f'{dir_landing_zone}/dados_extraidos.csv')\n",
    "\n",
    "        print('Resultado extraído com sucesso!')\n",
    "\n",
    "        return df_result\n",
    "    else:\n",
    "        print('Falha: Nenhum dado foi extraído da API!')\n",
    "\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27df6740-e46c-4aba-b7db-88e390e66a4e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Função para Carregamento dos dados extraídos (Bronze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eaae4763-2b22-4fdf-8ecc-30367f0e2e0e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_data(df_new : ps.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Concatena os dados extraídos para o parquet consolidado.\n",
    "    \n",
    "    Parâmetros:\n",
    "        df_new (ps.DataFrame): DataFrame com os dados extraídos da API.\n",
    "        \n",
    "    Retorno:\n",
    "        message (str): mensagem detalhando o sucesso ou falha da operação.\n",
    "    \"\"\"\n",
    "    \n",
    "    try: # Se tiver arquivos.\n",
    "        arquivo = dbutils.fs.ls(dir_bronze)         # Lista o arquivo se existir.\n",
    "        df_result = ps.read_parquet(dir_bronze)     # Carrega em df.\n",
    "        df_result = ps.concat([df_result, df_new])  # Concatena os novos dados no df consolidado.\n",
    "        \n",
    "        # Verificação de arquivos duplicados.\n",
    "        df_result = df_result.sort_values(by='data_load')\n",
    "        df_result = df_result.drop_duplicates(subset='key', keep='last')\n",
    "\n",
    "        df_result.to_parquet(dir_bronze)            # Exportar o df consolidade (Parquet).\n",
    "\n",
    "        message = 'Resultado carregado com sucesso!'\n",
    "\n",
    "    except Exception as e: # Se não tiver arquivos.\n",
    "        if 'java.io.FileNotFoundException' in str(e):\n",
    "            message = \"Arquivo não encontrado para load_data, primeiro processamento\"\n",
    "            df_new.to_parquet(dir_bronze)\n",
    "\n",
    "        else: \n",
    "            message = 'Erro na carga: ' + str(e)\n",
    "\n",
    "    # Remove os dados brutos que foram carregados.\n",
    "    dbutils.fs.rm(f'{dir_landing_zone}/dados_extraidos.csv', True)\n",
    "\n",
    "    return message\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b43aa21d-e578-4a11-bbf2-9416f8193d35",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Função para Limpeza dos dados (Silver)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aba8fb08-858a-4971-b4ea-182938bf9613",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def clear_data() -> bool:\n",
    "    \"\"\"\n",
    "    Função que limpa os dados consolidados.\n",
    "    \n",
    "    Parâmetros:\n",
    "        None\n",
    "    \n",
    "    Retorno:\n",
    "        bool (bool): valor de sucesso ou falha da execução da função.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Ler o dado consolidado.\n",
    "        df = ps.read_parquet(dir_bronze)\n",
    "\n",
    "        # Remover linhas com valores nulos.\n",
    "        df = df.dropna()\n",
    "\n",
    "        # Mudar tipo de dados da coluna publishedAt.\n",
    "        # Arrumar a data de publicação.\n",
    "        df['publishedAt'] = df['publishedAt'].apply(lambda x : x.split('T')[0])\n",
    "        df['publishedAt'] = ps.to_datetime(df['publishedAt'], format='%Y-%m-%d')\n",
    "\n",
    "        # Armazenar parquet limpo.\n",
    "        df.to_parquet(dir_silver)\n",
    "\n",
    "        print('Limpeza realizada com sucesso!')\n",
    "\n",
    "        return True\n",
    "    except:\n",
    "        print('Falha: não foi possível realizar a limpeza dos dados!')\n",
    "\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e70f9717-b2ca-443a-82e5-a3f6b1dfc5cd",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Função para Transformação dos dados (Gold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebdfded2-1ad8-412c-ac4b-360bf092b4ca",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def agrupar_by_data(df : ps.DataFrame) -> ps.DataFrame:\n",
    "    # Criar novas colunas.\n",
    "    df['Year'] = df['publishedAt'].dt.year\n",
    "    df['Month'] = df['publishedAt'].dt.month\n",
    "    df['Day'] = df['publishedAt'].dt.day\n",
    "\n",
    "    # Agrupar -> Por ano, mês e dia.\n",
    "    df = df.groupby(['Year', 'Month', 'Day']).agg(Qtde_noticias = ('title', 'Count'))\n",
    "\n",
    "    # Reinicia o index e não exclui o anterior.\n",
    "    df = df.reset_index(drop=False)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68092027-0c36-4672-a511-5fde32d9faad",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def transform_data() -> None:\n",
    "    \n",
    "    # Ler o dado limpo.\n",
    "    df = ps.read_parquet(dir_silver)\n",
    "\n",
    "    # 4.1 - Quantidade de notícias por ano, mês e dia de publicação;\n",
    "    df_groupDate = agrupar_by_data(df)\n",
    "\n",
    "    # 4.2 - Quantidade de notícias por fonte e autor;\n",
    "\n",
    "    # 4.3 - Quantidade de notícias por palavra-chave;\n",
    "\n",
    "    # Armazena o resultado transformado.\n",
    "    df_groupDate.to_parquet(dir_gold)\n",
    "\n",
    "    print('Transformação realizada com sucesso!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ddad01e2-06ce-453b-806f-63cf1a81b9e3",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "##### Função ELT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b321be46-0344-472d-9021-21482568ded6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def elt(current_datetime : str) -> None:\n",
    "    \"\"\"\n",
    "    Função que executa o processo de ELT.\n",
    "\n",
    "    Parâmetros:\n",
    "        current_datetime (str) : data para importar os dados.\n",
    "\n",
    "    Retorno:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"** inicializa o ELT **\\n\")\n",
    "\n",
    "    try: # Verifica se existe novos dados para serem processados.\n",
    "\n",
    "        # Faz a chamada da extração, da carga e da transformação dos dados.\n",
    "        df_new = extract_data(current_datetime)\n",
    "\n",
    "        if df_new != None: # Verifica se ocorreu a extração de dados corretamente.\n",
    "            message = load_data(df_new)\n",
    "            if message == 'Resultado carregado com sucesso!' or message == \"Arquivo não encontrado para load_data, primeiro processamento\": # Verifica se conseguiu carregar os dados.\n",
    "                print(message)\n",
    "                limpou = clear_data()\n",
    "                if limpou: # Verifica se conseguiu limpar os dados.\n",
    "                    transform_data()\n",
    "                    message = '\\n** ELT realizado com sucesso! **\\n'\n",
    "        else:\n",
    "            message = '\\n** ELT interrompido! **\\n'\n",
    "\n",
    "    except Exception as e: #caso não exista nenhum dado novo, retorna com a mensagem e encerra o processo\n",
    "            message = '\\nErro no ELT:' + str(e) + '\\n'\n",
    "    \n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8db3ad00-9b63-447d-bcea-30e686adb71f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9c8fd269-c29a-4dcf-b411-4997209efcaa",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[270]: \"\\ncurrent_datetime = '2024-04-04'\\n# Faz a chamada da extração, da carga e da transformação dos dados.\\ndf_new = extract_data(current_datetime)\\ndf_new.shape\\n\""
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "current_datetime = '2024-04-04'\n",
    "# Faz a chamada da extração, da carga e da transformação dos dados.\n",
    "df_new = extract_data(current_datetime)\n",
    "df_new.shape\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2932bc2d-e2e0-4adb-8564-679bb0139138",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[271]: '\\nif df_new: # Verifica se ocorreu a extração de dados corretamente.\\n    message = load_data(df_new)\\n    print(message)\\n'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "if df_new: # Verifica se ocorreu a extração de dados corretamente.\n",
    "    message = load_data(df_new)\n",
    "    print(message)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "949eaafc-5a68-4f9d-b8e1-574e69d06785",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#load_data(df_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "45a4bba5-68ca-4546-9e82-f96d62d8a7eb",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Webhook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fa261712-5a25-4019-95fc-0a2aaee119cb",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [06/Apr/2024 02:07:37] \"POST /webhook HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Received data: {'message': 'Processa o ELT, por favor \\n', 'current_datetime': '2024-03-10'}\n",
      "** inicializa o ELT **\n",
      "\n",
      "Sem dados de retorno via API\n",
      "Falha: Nenhum dado foi extraído da API!\n",
      "\n",
      "** ELT interrompido! **\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Inicialização da aplicação Flask\n",
    "app = flask.Flask(__name__)\n",
    "\n",
    "# Definição da rota \"/webhook\" com suporte a requisições HTTP POST\n",
    "@app.route(\"/webhook\", methods=[\"POST\"])\n",
    "def handle_webhook():\n",
    "    # Recupera o conteúdo da requisição como um dicionário em Python\n",
    "    data = flask.request.get_json()\n",
    "    \n",
    "    # Imprime o conteúdo da requisição\n",
    "    print(\"Received data:\", data)\n",
    "    \n",
    "    # Data recebida.\n",
    "    current_datetime = data.get('current_datetime')\n",
    "\n",
    "    # Executar o elt.\n",
    "    message = elt(current_datetime)\n",
    "\n",
    "    # Mostra a mensagem!\n",
    "    print(message)\n",
    "\n",
    "    # Retorna uma resposta HTTP simples\n",
    "    return message\n",
    "\n",
    "# Verifica se o script está sendo executado como um módulo principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Inicia a execução da aplicação\n",
    "    #app.run(host='0.0.0.0', port=5000)\n",
    "    app.run()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Webhook Rodar",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
